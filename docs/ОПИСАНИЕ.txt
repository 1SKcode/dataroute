# ETL-routes система
# Система для создания ETL-процессов через редактируемые файлы

## Технологический стек
- Python
- Pydantic для валидации
- Asyncio для асинхронности

## Архитектура
- Объектно-блочный конструктор
- Модульная структура
- Плагинная система

## Основные компоненты
1. Parser - парсинг конфигурационных файлов
2. Validator - валидация схем и данных
3. Executor - выполнение ETL-процессов
4. Monitor - мониторинг и логирование

## Особенности
- Горячая перезагрузка конфигурации
- Распределенное выполнение
- Отказоустойчивость
- Масштабируемость
- Метрики и алерты




Вводные:    Есть n кол-во баз данных (или других источников), в которых есть n кол-во таблиц.
Цель:       Написать цепочку ETL для достижения требуемого состояния данных
Проблема:   Классический ETL через Python-скрипты — это хорошо, но если появляются нестандартные ситуации, то возникают трудности, к ним можно отнести:
            - кастомные правила трансформации
            - частые изменения в логике
            - разные источники
            - условные конструкции и словари
            - нестабильные данные

Решение:    Создание etl-route системы, которая создает ETl процессы динамически по архитектуре объектно-блочного конструктора через обычные редактируемые файлы

Требования к системе:
            - O(N). Время выполнения зависит от количества объектов линейно
            - Асинхронность: максимальное использование ресурсов и масштабируемость
            - Отказоустойчивость: механизм откатов и восстановления
            - Оперирование объектами: все — объекты (таблицы, поля, правила)
            - Построение etl-route через конструктор
            - Архитектура под расширяемость и внедрения нового ф-нала



Пример использования: Нужен ETL, который переливает данные из одной таблицы в другую,
но с достаточно гибкой структурой преобразовательных правил, фильров, с использованием словарей и условных конструкций
При этом избавиться от нужды каждый раз ходить в пайтон скрипт править код при необходимости добавить новую логику




Вот эта карта:
А - Начальные источники данных с первичными необработанными данными - source
T - Фильтры, преобразователи, условные ветвления - route_map
B - Конечные источники данных с обработанными данными - target
N - Нотификации об ошибках - внедрена в route_map

Для простого примера возьмем постгрес и одну базу данных с двумя таблицами. 
1. Есть файл .env, в котором указаны параметры подключения к базе данных:
# Для POINT_NAME1
POINT_NAME1=value
POINT_TYPE1=value
HOST1=value
PORT1=value
USER1=value
PASS1=value
BDNM1=value

# Для POINT_NAME2
POINT_NAME2=value
POINT_TYPE2=value
HOST2=value
PORT2=value
USER2=value
PASS2=value
BDNM2=value


2. Настройка самого пр
conns:  



```


[id](any) -> [id](int8) На вход берем ключ id, он может быть любого типа, а в конечную точку записываем это значение как id с типом int8 
[name](any) -> |norm_srt| -> [nameNorm](text) -- На вход берем ключ name (тоже any), затем ищем и вызываем ф-ию norm_str, передаем в нее name, а затем записываем в nameNorm с типом text
[nickname](text) -> |strip|lower| -> [nicknameNorm](text) - Тут уже показана цепочка со встроенными преобразованиями
[role](test) -> |trim|to_lower|replace("role", "роль") -> [roleNorm](test) - цепочка со встроенными преобразованиями + передача во встроенную ф-ию аргументы)
[age](any) 

```

Для достижения цели необходио реализовать:
1. Создание DSL
2. Написание лексера для DLS (Lark)
3. Написание стандартных функций

4. Использование словарей

5. Написание логических операций



1. Создание синтаксиса и грамматики DSL (ГОТОВО, возможны правки) +2ч
2. Реализация парсера с помощью Lark (пайтон библиотека) +1д
- Построение дерева разбора (AST)
- Интерпретация AST
- Валидация синтаксиса

3. Трансформация AST в промежуточное представление +3ч
- JSON-структура с деталями инструкции

4. Генерация Python-инструкций из промежуточного представления +1д
- Возможность генерации как строк, так и AST-моделей Python (через ast или шаблоны Jinja2).
- Встраивание стандартных функций
- Обработка условий и циклов

5. Вызов и выполнение Python-сценариев +1д
- при вызове сканируется папка etl_routes/routes и вызывается соответствующий файл
- запускается интерпретатор DSL


Дополнительно: +5ч
- интеграция с нотификацией
- логированеи
- откаты
- встроенные функции (s1, get)




Вызов из Python кода:
start_etl(dict, "route_name", "route_type", "rules.?")

Ищется файл route_name.py в папке  etl_routes/routes

Его содержимое:




